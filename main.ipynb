{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Google Colabで実装を行なったため、main.pyは使用しておりません。実行する場合はfileのpathなどを適宜変更してもらえればと思います。また、本ノートブックでは9個のモデルの出力結果を結合していますが、それぞれのモデルのファインチューニングと出力に5~8時間ほどかかると思われます。自身の実装環境ではそれぞれのモデルを別々に訓練しており、時間が足りなかったため本ノートブックを通しで実行して検証することができませんでした。パラメータなどは再確認したためエラーはないと思いますが、万が一の場合はお手数おかけいたします、、、"
      ],
      "metadata": {
        "id": "OUy_tISjAkG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. データ読み込み**"
      ],
      "metadata": {
        "id": "tjG5Kpv6ycP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTHaGFv7xt59"
      },
      "outputs": [],
      "source": [
        "! pip install accelerate\n",
        "! pip install --upgrade bitsandbytes -i https://pypi.org/simple/\n",
        "! pip install --upgrade transformers\n",
        "! pip install datasets\n",
        "! pip install peft\n",
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/VQA_final/VQA/train.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "YV9r586Pxurh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import time\n",
        "from statistics import mode\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(83)"
      ],
      "metadata": {
        "id": "j4XN-H4lx0KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "from torchvision import transforms\n",
        "from collections import Counter\n",
        "from datasets import Dataset, Features, Value, Image\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def createDataset(image_folder, json_path):\n",
        "    trainList = []\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        for k in tqdm(range(len(data['image']))):\n",
        "            image = data['image'][str(k)]\n",
        "            question = data['question'][str(k)]\n",
        "            answers = data['answers'][str(k)]\n",
        "            options = [entry[\"answer\"] for entry in answers]\n",
        "            answer_counts = Counter(options)\n",
        "            mode_answer = answer_counts.most_common(1)[0][0]\n",
        "            temp = []\n",
        "            temp.append(mode_answer)\n",
        "            temp.append(question)\n",
        "            temp.append(image_folder + image)\n",
        "            trainList.append(temp)\n",
        "\n",
        "        f.close()\n",
        "    labels = ['answer', 'question', 'image']\n",
        "    df = pd.DataFrame.from_records(trainList, columns=labels)\n",
        "    features = Features({\n",
        "      'answer': Value('string'),\n",
        "      'question': Value('string'),\n",
        "      'image': Image()\n",
        "    })\n",
        "\n",
        "    dataset = Dataset.from_pandas(df, features=features)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = createDataset(\"/tmp/train/\", '/content/drive/MyDrive/Colab Notebooks/VQA_final/VQA/train.json')"
      ],
      "metadata": {
        "id": "zZ4mSOisx11n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PaliGemmaProcessorを使用しデータをエンコーディングする\n",
        "def collate_fn(examples):\n",
        "  texts = [\"answer en \" + example[\"question\"] for example in examples]\n",
        "  labels= [example['answer'] for example in examples]\n",
        "  images = [example[\"image\"].convert(\"RGB\") for example in examples]\n",
        "  tokens = processor(text=texts, images=images, suffix=labels,\n",
        "                    return_tensors=\"pt\", padding=\"longest\",\n",
        "                    tokenize_newline_separately=False)\n",
        "\n",
        "  tokens = tokens.to(torch.bfloat16).to(device)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "1KOrTk8QyHHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. モデルのパラメータ定義**"
      ],
      "metadata": {
        "id": "2OTS0KONyoUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "\n",
        "#PaliGemmaモデルにアクセスするためにhuggingfaceのreadトークンとwriteトークンを登録してください\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "rUWLdIy7x5q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model_ids = [\n",
        "    \"google/paligemma-3b-ft-vqav2-224\",\n",
        "    \"google/paligemma-3b-ft-gqa-224\",\n",
        "    \"google/paligemma-3b-ft-tallyqa-224\",\n",
        "    \"google/paligemma-3b-ft-stvqa-224\",\n",
        "    \"google/paligemma-3b-ft-textvqa-224\",\n",
        "    \"google/paligemma-3b-ft-aokvqa-da-224\",\n",
        "    \"google/paligemma-3b-pt-224\",\n",
        "    \"google/paligemma-3b-ft-ocrvqa-224\",\n",
        "    \"google/paligemma-3b-ft-okvqa-224\"\n",
        "]\n",
        "\n",
        "#LoRAファインチューニングのパラメータ\n",
        "lora_configs = [\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      lora_dropout=0.05,\n",
        "      use_rslora=True,\n",
        "      lora_alpha=16,\n",
        "      bias=\"none\",\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      lora_dropout=0.05,\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "    LoraConfig(\n",
        "      r=8,\n",
        "      target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "      task_type=\"CAUSAL_LM\",\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "AlSKSljT1gch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "lr = 1e-5\n",
        "\n",
        "#訓練時ののtrainerのパラメータ\n",
        "training_args = [\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=6,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=1e-4,\n",
        "      adam_epsilon=1e-8,\n",
        "      adam_beta2=0.999,\n",
        "      max_grad_norm=3.0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=6,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=1e-4,\n",
        "      adam_epsilon=1e-8,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=6,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=0,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=6,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=0,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=7,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=0,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=7,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=0,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=10,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=1e-5,\n",
        "      max_grad_norm=10.0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=8,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=0,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "    TrainingArguments(\n",
        "      num_train_epochs=6,\n",
        "      remove_unused_columns=False,\n",
        "      per_device_train_batch_size=10,\n",
        "      gradient_accumulation_steps=4,\n",
        "      warmup_steps=2,\n",
        "      learning_rate=lr,\n",
        "      weight_decay=0,\n",
        "      adam_beta2=0,\n",
        "      logging_steps=100,\n",
        "      optim=\"adamw_hf\",\n",
        "      push_to_hub=False,\n",
        "      dataloader_pin_memory=False,\n",
        "      lr_scheduler_type=\"linear\",\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "9pxp_GEv-UdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. ファインチューニングと推論**"
      ],
      "metadata": {
        "id": "voPV0_SOBF4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig, PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
        "from peft import get_peft_model\n",
        "\n",
        "def load_model(model_id, lora_config):\n",
        "    #PaliGemmaモデルの読み込み\n",
        "    model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)\n",
        "    processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
        "\n",
        "    #QLoRAファインチューニングの設定\n",
        "    for param in model.vision_tower.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    for param in model.multi_modal_projector.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, torch_dtype=torch.bfloat16)\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    return model, processor\n",
        "\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# 各モデルをファインチューニングし、推論を行う\n",
        "for i in range(len(model_ids)):\n",
        "    model, processor = load_model(model_ids[i], lora_configs[i])\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=collate_fn,\n",
        "        args=training_args[i],\n",
        "    )\n",
        "    trainer.train()\n",
        "\n",
        "    submission = []\n",
        "    batch_size = 16\n",
        "    image_paths = []\n",
        "    questions = []\n",
        "\n",
        "    # データをロード\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/VQA_final/VQA/valid.json', 'r') as f:\n",
        "        data = json.load(f)\n",
        "        for k in range(len(data['image'])):\n",
        "            image_paths.append('/tmp/valid/' + data['image'][str(k)])\n",
        "            questions.append(data['question'][str(k)])\n",
        "\n",
        "    # バッチ処理\n",
        "    for j in tqdm(range(0, len(image_paths), batch_size)):\n",
        "        batch_image_paths = image_paths[j:j + batch_size]\n",
        "        batch_questions = questions[j:j + batch_size]\n",
        "\n",
        "        images = [Image.open(path).convert(\"RGB\") for path in batch_image_paths]\n",
        "        inputs = processor(batch_questions, images, return_tensors=\"pt\", padding=True).to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "\n",
        "        batch_submission = [processor.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "        submission.extend(batch_submission)\n",
        "\n",
        "    # 出力の形を調整\n",
        "    def extract_after_newline(item):\n",
        "        return item.split('\\n')[-1]\n",
        "\n",
        "    submission = np.array([extract_after_newline(item) for item in submission])\n",
        "    predictions.append(submission)\n",
        "\n",
        "    # GPUメモリを解放\n",
        "    del model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Yldc2RDhyBij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. アンサンブル**"
      ],
      "metadata": {
        "id": "tCIVzv_4D1O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "\n",
        "def weighted_ensemble(predictions, weights):\n",
        "    num_samples = len(predictions[0])\n",
        "\n",
        "    ensembled_predictions = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        #各出力結果の回数を数え、重みを追加していく\n",
        "        counter = Counter()\n",
        "        for pred, weight in zip(predictions, weights):\n",
        "            counter[pred[i]] += weight\n",
        "\n",
        "        #一番重みの合計が高い答えを選択\n",
        "        ensembled_predictions.append(counter.most_common(1)[0][0])\n",
        "\n",
        "    return np.array(ensembled_predictions)\n",
        "\n",
        "\n",
        "weights = [0.2, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "ensembled_result = weighted_ensemble(predictions, weights)\n",
        "np.save('submission.npy', ensembled_result)"
      ],
      "metadata": {
        "id": "yyw1yKlfD4eD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}